{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from IPython.display import Image  # for displaying images\n",
    "import os \n",
    "import random\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xml.etree.ElementTree as ET\n",
    "from xml.dom import minidom\n",
    "from tqdm import tqdm\n",
    "from PIL import Image, ImageDraw\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "random.seed(108)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get the data from XML Annotation\n",
    "def extract_info_from_xml(xml_file):\n",
    "    root = ET.parse(xml_file).getroot()\n",
    "\n",
    "    # Initialise the info dict\n",
    "    info_dict = {}\n",
    "    info_dict['bboxes'] = []\n",
    "\n",
    "    # Parse the XML Tree\n",
    "    for elem in root:\n",
    "        # Get the file name\n",
    "        if elem.tag == \"filename\":\n",
    "            info_dict['filename'] = elem.text\n",
    "\n",
    "        # Get the image size\n",
    "        elif elem.tag == \"size\":\n",
    "            image_size = []\n",
    "            for subelem in elem:\n",
    "                if subelem.text is not None: # .tag != \"depth\": \n",
    "                    image_size.append(int(subelem.text))\n",
    "\n",
    "            info_dict['image_size'] = tuple(image_size)\n",
    "\n",
    "        # Get details of the bounding box\n",
    "        elif elem.tag == \"object\":\n",
    "            bbox = {}\n",
    "            for subelem in elem:\n",
    "                if subelem.tag == \"name\":\n",
    "                    bbox[\"class\"] = subelem.text\n",
    "\n",
    "                elif subelem.tag == \"bndbox\":\n",
    "                    for subsubelem in subelem:\n",
    "                        bbox[subsubelem.tag] = int(float(subsubelem.text))\n",
    "            info_dict['bboxes'].append(bbox)\n",
    "\n",
    "    return info_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bboxes': [{'class': 'D00', 'xmin': 1138, 'ymin': 1281, 'xmax': 1169, 'ymax': 1336}, {'class': 'D20', 'xmin': 1537, 'ymin': 1131, 'xmax': 1629, 'ymax': 1247}, {'class': 'D00', 'xmin': 1773, 'ymin': 1825, 'xmax': 1862, 'ymax': 2038}, {'class': 'D00', 'xmin': 1589, 'ymin': 1296, 'xmax': 1624, 'ymax': 1343}, {'class': 'D00', 'xmin': 1507, 'ymin': 1216, 'xmax': 1527, 'ymax': 1254}], 'filename': 'Norway_000000.jpg', 'image_size': (3650, 2044)}\n"
     ]
    }
   ],
   "source": [
    "print(extract_info_from_xml('Norway/train/annotations/xmls/Norway_000000.xml'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary that maps class names to IDs\n",
    "class_name_to_id_mapping = {\"D00\": 1,\n",
    "                           \"D10\": 2,\n",
    "                           \"D20\": 3,\n",
    "                           \"D40\": 4}\n",
    "\n",
    "# Convert the info dict to the required yolo format and write it to disk\n",
    "def convert_to_yolov5(info_dict):\n",
    "    print_buffer = []\n",
    "\n",
    "    # For each bounding box\n",
    "    for b in info_dict[\"bboxes\"]:\n",
    "        try:\n",
    "            class_id = class_name_to_id_mapping[b[\"class\"]]\n",
    "        except KeyError:\n",
    "            print(\"Invalid Class. Must be one from \", class_name_to_id_mapping.keys())\n",
    "\n",
    "        # Transform the bbox co-ordinates as per the format required by YOLO v5\n",
    "        b_center_x = (b[\"xmin\"] + b[\"xmax\"]) / 2\n",
    "        b_center_y = (b[\"ymin\"] + b[\"ymax\"]) / 2\n",
    "        b_width    = (b[\"xmax\"] - b[\"xmin\"])\n",
    "        b_height   = (b[\"ymax\"] - b[\"ymin\"])\n",
    "\n",
    "        # Normalise the co-ordinates by the dimensions of the image\n",
    "        image_w, image_h = info_dict[\"image_size\"]\n",
    "        b_center_x /= image_w\n",
    "        b_center_y /= image_h\n",
    "        b_width    /= image_w\n",
    "        b_height   /= image_h\n",
    "\n",
    "        #Write the bbox details to the file\n",
    "        print_buffer.append(\"{} {:.3f} {:.3f} {:.3f} {:.3f}\".format(class_id, b_center_x, b_center_y, b_width, b_height))\n",
    "\n",
    "    # Name of the file which we have to save\n",
    "    save_file_name = os.path.join(\"Norway/train/annotations/xmls\", info_dict[\"filename\"].replace(\"jpg\", \"txt\"))\n",
    "\n",
    "    # Save the annotation to disk\n",
    "    print(\"\\n\".join(print_buffer), file= open(save_file_name, \"w\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 47/8161 [01:30<3:15:45,  1.45s/it] "
     ]
    }
   ],
   "source": [
    "# Get the annotations\n",
    "annotations = [os.path.join('Norway/train/annotations/xmls', x) for x in os.listdir('Norway/train/annotations/xmls') if x[-3:] == \"xml\"]\n",
    "annotations.sort()\n",
    "\n",
    "# Convert and save the annotations\n",
    "for ann in tqdm(annotations):\n",
    "    info_dict = extract_info_from_xml(ann)\n",
    "    convert_to_yolov5(info_dict)\n",
    "annotations = [os.path.join('Norway/train/annotations/xmls', x) for x in os.listdir('Norway/train/annotations/xmls') if x[-3:] == \"txt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#annotations = [os.path.join('labels/train', x) for x in os.listdir('labels/train') if x[-3:] == \"txt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#random.seed(20)\n",
    "\n",
    "class_id_to_name_mapping = dict(zip(class_name_to_id_mapping.values(), class_name_to_id_mapping.keys()))\n",
    "\n",
    "def plot_bounding_box(image, annotation_list):\n",
    "    annotations = np.array(annotation_list)\n",
    "    w, h = image.size\n",
    "    #print(len(annotation_list))\n",
    "    if len(annotation_list[0]) < 4:\n",
    "        plotted_image = ImageDraw.Draw(image)\n",
    "    else:\n",
    "        plotted_image = ImageDraw.Draw(image)\n",
    "        transformed_annotations = np.copy(annotations)\n",
    "        #print(transformed_annotations)\n",
    "        transformed_annotations[:,[1,3]] = annotations[:,[1,3]] * w\n",
    "        transformed_annotations[:,[2,4]] = annotations[:,[2,4]] * h\n",
    "        #print(transformed_annotations)\n",
    "\n",
    "        transformed_annotations[:,1] = transformed_annotations[:,1] - (transformed_annotations[:,3] / 2)\n",
    "        transformed_annotations[:,2] = transformed_annotations[:,2] - (transformed_annotations[:,4] / 2)\n",
    "        transformed_annotations[:,3] = transformed_annotations[:,1] + transformed_annotations[:,3]\n",
    "        transformed_annotations[:,4] = transformed_annotations[:,2] + transformed_annotations[:,4]\n",
    "        #print(transformed_annotations)\n",
    "\n",
    "        for ann in transformed_annotations:\n",
    "            obj_cls, x0, y0, x1, y1 = ann\n",
    "            plotted_image.rectangle(((x0,y0), (x1,y1)), width = 10, outline =\"red\")\n",
    "\n",
    "            plotted_image.text((x0, y0 - 10), class_id_to_name_mapping[(int(obj_cls))])\n",
    "\n",
    "    plt.imshow(np.array(image))\n",
    "    plt.show()\n",
    "\n",
    "# Get any random annotation file\n",
    "annotation_file = random.choice(annotations)\n",
    "with open(annotation_file, \"r\") as file:\n",
    "    annotation_list = file.read().split(\"\\n\")[:-1]\n",
    "    annotation_list = [x.split(\" \") for x in annotation_list]\n",
    "    annotation_list = [[float(y) if y != \"\" else 0 for y in x ] for x in annotation_list]\n",
    "    \n",
    "#Get the corresponding image file\n",
    "image_file = annotation_file.replace(\"labels\", \"images\").replace(\"txt\", \"jpg\")\n",
    "print(image_file)\n",
    "print(annotation_file)\n",
    "assert os.path.exists(image_file)\n",
    "\n",
    "#Load the image\n",
    "image = Image.open(image_file)\n",
    "\n",
    "#Plot the Bounding Box\n",
    "#print(annotation_list)\n",
    "plot_bounding_box(image, annotation_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read images and annotations\n",
    "images = [os.path.join('Norway/train/images/train', x) for x in os.listdir('Norway/train/images/train')]\n",
    "annotations = [os.path.join('Norway/train/annotations/xmls', x) for x in os.listdir('Norway/train/annotations/xmls') if x[-3:] == \"txt\"]\n",
    "\n",
    "images.sort()\n",
    "annotations.sort()\n",
    "\n",
    "# Split the dataset into train-valid-test splits\n",
    "train_images, val_images, train_annotations, val_annotations = train_test_split(images, annotations, test_size = 0.2, random_state = 1)\n",
    "val_images, test_images, val_annotations, test_annotations = train_test_split(val_images, val_annotations, test_size = 0.5, random_state = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir images labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir images/train images/val images/test labels/train labels/val labels/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Utility function to move images\n",
    "def move_files_to_folder(list_of_files, destination_folder):\n",
    "    for f in list_of_files:\n",
    "        try:\n",
    "            shutil.move(f, destination_folder)\n",
    "        except:\n",
    "            print(f)\n",
    "            assert False\n",
    "\n",
    "# Move the splits into their folders\n",
    "move_files_to_folder(train_images, 'images/train')\n",
    "move_files_to_folder(val_images, 'images/val/')\n",
    "move_files_to_folder(test_images, 'images/test/')\n",
    "move_files_to_folder(train_annotations, 'labels/train/')\n",
    "move_files_to_folder(val_annotations, 'labels/val/')\n",
    "move_files_to_folder(test_annotations, 'labels/test/')\n",
    "#!mv annotations labels\n",
    "#%cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "6bc455d8f55f52b007107ab8068de5c95f9f4fe0880ae5893ba5540acb89a7b5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
